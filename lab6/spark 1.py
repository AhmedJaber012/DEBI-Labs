from pyspark.sql import SparkSession

def main():

    # 1ï¸âƒ£ Create Spark Session
    spark = SparkSession.builder \
        .appName("Spark SQL Financial Project") \
        .enableHiveSupport() \
        .getOrCreate()

    spark.sparkContext.setLogLevel("ERROR")
    print("ðŸš€ Spark SQL Started")

    # 2ï¸âƒ£ Read CSV File
    df = spark.read \
        .option("header", "true") \
        .option("inferSchema", "true") \
        .csv("transactions.csv")

    print("ðŸ“„ Source Data")
    df.show()

    # 3ï¸âƒ£ Create Temp View
    df.createOrReplaceTempView("transactions")

    # 4ï¸âƒ£ Total Sales
    print("ðŸ’° Total Sales")
    spark.sql("""
        SELECT SUM(amount) AS total_sales
        FROM transactions
    """).show()

    # 5ï¸âƒ£ Average Transaction Value
    print("ðŸ“Š Average Transaction Value")
    spark.sql("""
        SELECT AVG(amount) AS avg_transaction
        FROM transactions
    """).show()

    # 6ï¸âƒ£ Top 5 Customers
    print("ðŸ† Top 5 Customers")
    spark.sql("""
        SELECT
            customer_id,
            SUM(amount) AS total_spent
        FROM transactions
        GROUP BY customer_id
        ORDER BY total_spent DESC
        LIMIT 5
    """).show()

    # 7ï¸âƒ£ Daily Sales
    print("ðŸ“† Daily Sales")
    spark.sql("""
        SELECT
            transaction_date,
            SUM(amount) AS daily_sales
        FROM transactions
        GROUP BY transaction_date
        ORDER BY transaction_date
    """).show()

    # 8ï¸âƒ£ Sales By City
    print("ðŸ™ï¸ Sales By City")
    spark.sql("""
        SELECT
            city,
            SUM(amount) AS total_sales
        FROM transactions
        GROUP BY city
        ORDER BY total_sales DESC
    """).show()

    # 9ï¸âƒ£ Suspicious Transactions
    print("ðŸš¨ Suspicious Transactions (amount > 5000)")
    spark.sql("""
        SELECT *
        FROM transactions
        WHERE amount > 5000
    """).show()

    # ðŸ”Ÿ Save Results
    spark.sql("""
        SELECT *
        FROM transactions
    """).write.mode("overwrite").parquet("output/transactions_parquet")

    spark.sql("""
        SELECT
            transaction_date,
            SUM(amount) AS daily_sales
        FROM transactions
        GROUP BY transaction_date
    """).write.mode("overwrite").csv(
        "output/daily_sales", header=True
    )

    print("âœ… Data Saved Successfully")

    # ðŸ”š Stop Spark
    spark.stop()
    print("ðŸ›‘ Spark Session Stopped")


if __name__ == "__main__":
    main()
